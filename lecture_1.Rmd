---
title: "Lecture 1 - Introduction to the course"
author: "Author: Matthew J. Cossley"
date: "Last update: `r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    toc: true
    toc_float:
        collapsed: true
        smooth_scroll: true
    toc_depth: 3
    fig_caption: yes
    # code_folding: show
    number_sections: false
    theme: cosmo
fontsize: 14pt
---

## What is computational neuroscience?

* Computational neuroscience is just using computers to
study brains.

* What counts as *brains* has come to refer to pretty much
anything across a very wide range of levels. E.g.,

  * Biochemical and electrical signal transduction and
  prorogation within individual cell compartments.
  
  * Intracellular signalling cascades.
  
  * Whole cell action potential spiking properties.
  
  * Collection of neurons as dynamical systems.
  
  * Local field potential, hemodynamic response, cortical
  oscillatory patterns.
  
  * Behaviour (e.g., decision making, action selection and
  execution)
  
* Using computers to study purely neural systems -- without
concern for behaviour -- is pretty fairly called
*computational neuroscience*.

* Using computers to study behaviour -- without concern for
neural systems -- would fall more naturally under the banner
of *cognitive modelling*.

* Using computers to study how the brain drives behaviour --
i.e., explicitly caring about both neural and cognitive
domains and trying to link them  -- is sometimes given
special names like *computational cognitive neuroscience*.


## Marr's levels

* **Computational**: A specification of what a system does
and why it does it.

* **Algorithmic**: A specification of how it does what it
does (i.e., what process is followed).

* **implementational**: A specification of how the system is
implemented in the brain.

* In my opinion, few models cleanly reside at a single one
of these levels and many probably are best classified
between levels. Even so, the conceptual divisions they get
us thinking about are useful to have on hand.


## Why computers?

* Mathematics is at the heart of computational neuroscience.

* The goal is to write down equations that formally describe
the process through which the phenomena of interest are
hypothesised to emerge.

* The need for computers arises when the mathematics that
you write down is complicated and difficult to evaluate.

* Computational approaches give us tools to deal with these
difficult mathematical situations. Well, some of them at
least.


## What is the real value gained? 

* Have you ever stuggled or argued with yourelf or others
about what a certain hypothesis predicts in a particular
experiment?

* Mathematical precision makes science happy. It eliminates
ambiguity and thereby makes mathematical models more
falsifiable.

* In practice, the word *more* in the last sentence above
can do an awful lot of work. Coming up with experiments that
are strong tests of any model, even mathematically precise
models, can be very difficult.

* Even so, there is no question that mathematics and
computers help... and sometimes they help a whole lot.


## Why Python
* It is a real programming language
* It is mature
* It is widely embraced in psychology and neuroscience
* It is widely embraced inside and outside academia 
* It is widely used in the machine learning community
* It is relatively easy to learn


## Getting started with Python

* I recommend getting started with
[Anaconda](https://www.anaconda.com/products/individual).

* Anaconda will provide the IDE
[Spyder](https://www.spyder-ide.org) which will be a good
place for most of you to start working with Python.

* However, there are many Python programming tools to choose
from. Use what you like.


## Learning Python

* Just like with other programming languages you have been
exposed to, the base functionality of Python is extended by
external libraries. We will make heavy use of the following
libraries:

* [Numpy](https://numpy.org)

  * [Learn Numpy](https://numpy.org/learn/)

* [Matplotlib](https://matplotlib.org/stable/index.html)

  * [Learn Matplotlib](https://matplotlib.org/stable/tutorials/index.html)
  

## Differential equations

* The HH model and lots of other models we will encounter
are ultimately expressed in *differential equations*.

* A differential equation is essentially an equation that
relates some function $f(x)$ to its derivative
$\frac{d}{dx}f(x)$ 

* The derivative $\frac{d}{dx}f(x)$ is the **rate of
change** of the function $f(x)$ with respect to the variable
$x$. If $x$ changes by an infinitesimal amount,
$\frac{d}{dx}f(x)$ reports how much $f(x)$ will change in
response.

* A generic differential equation is as follows:

$$\frac{d}{dx}f(x) = g(x)$$

* You can read this in words as saying that the rate of
change of $f(x)$ with respect to $x$ --- given by
$\frac{d}{dx}f(x)$ --- is described by some other function
$g(x)$.

* To solve a differential equation, we need to find a
definition for $f(x)$ that makes the equation true.

* For example, if $g(x)$ then:

$$\frac{d}{dx}f(x) = x$$

* We can see that $f(x) = \frac{1}{2}x^2$ solves the
differential equation, because 

$$
\begin{align}
\frac{d}{dx}f(x) &= \frac{d}{dx}\frac{1}{2}x^2 \\
                 &= \frac{1}{2} \frac{d}{dx} x^2 \\
                 &= \frac{2}{2} x \\
                 &= x
\end{align}
$$

* In general, the solution to any differential equation can
be computed via integration $f(x) = \int \frac{d}{dx} f(x) dx$.

* However, in practice, the differential equations we will
want to solve are too complex to solve using either
intuition or by explicitly evaluating integrals.


## Euler's method

* Euler's method is a simple method to solve differential
equations that can be applied in situations were a closed
analytical solution cannot be easily obtained.

* Euler's method says this:

$$f(x_2) \approx f(x_1) + \frac{d}{dx} f(x) \Bigg\rvert_{x=x_1} \Delta x$$

* In words, this says that the value of $f(x_2)$ is
approximately equal to $f(x_1)$ plus how much it changed
from $x_1$ to $x_2$.

* The *how much it was likely to change* bit is computed by
taking the derivative evaluated at $x_1$ and multiplying by
the total change in $x$, given by $\Delta x = x_2 - x_1$.

* Here's how to implement Euler's method in `python`: 

```{r setup, include=FALSE}
library(reticulate)
use_python('/Users/mq20185996/miniconda3/bin/python')
```

```{python message=FALSE}
import numpy as np
import matplotlib.pyplot as plt

# define the range over which to approximate fx
x = np.arange(0, 5, 0.01)

# initialise fx to zeros
fx = np.zeros(x.shape)

# Euler's method requires we specify an initial value
fx[0] = 1

for i in range(1, x.shape[0]):
  # df/dx = x
  dfxdx = x[i-1]
  
  # delta x
  dx = x[i] - x[i-1]
  
  # Euler's update
  fx[i] = fx[i-1] + dfxdx * dx
  
# plot solution
# It should look like 1/2 x^2
fig, ax, = plt.subplots(1, 1, squeeze=False)
ax[0, 0].plot(x, fx)
ax[0, 0].set_ylabel('f(x)')
ax[0, 0].set_xlabel('x')
plt.show()
```