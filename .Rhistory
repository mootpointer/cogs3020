library(ggplot2)
library(latex2exp)
rm(list = ls())
files_in <- list.files("../val_results", pattern = "in_exp_1", full.names=T)
files_out <- list.files("../val_results", pattern = "out_exp_1", full.names=T)
?rm
?ls
?rm
?ls
?if
()
?for (variable in vector) {
}
?if
()
?sum
shiny::runApp('Dropbox/teaching/cogs2020/shiny/test')
library(data.table) # You should know this
library(ggplot2) # You should know this too
library(curl) # This is new... it lets us read data from the web
rm(list=ls())
fp <- "https://crossley.github.io/cogs2020/data/data_lecture_1_survey/survey_data.csv"
d <- fread(fp)
d
d[, length(unique(ppt))]
d[, .N, .(ppt)][N==13, .N]
d[, mean(confidence)]
# We have to exclude the people that did not answer all 13 questions, because
# we don't know which question their answers correspsond too.
dd <- d[, .(confidence, question, .N), .(ppt)][N==13]
ggplot(dd, aes(x=question, y=confidence)) +
geom_point() +
facet_wrap(~ppt, ncol=3)
n_success <- 9 # The number of people that took the survey
n_total <- 22 # The total number of people that could have taken the survey
p_null <- 0.5 # The probability that a fair coin would take the survey
p_hat = pbinom(n_success, n_total, p_null)
p_hat
mu_null <- 5
t.test(d[, confidence], mu=mu_null, alternative='greater')
1 + 1
library(learnr)
library(data.table) # You should know this
library(ggplot2) # You should know this too
library(curl) # This is new... it lets us read data from the web
rm(list=ls())
fp <- "https://crossley.github.io/cogs2020/data/data_lecture_1_survey/survey_data.csv"
d <- fread(fp)
d
d[20:40]
d[ppt==5]
d[question==2 | question==7]
d[question %in% c(2, 7)]
d[, .N]
d[, .N, .(question)]
d[order(confidence)]
d[order(-confidence)]
d[, confidence]
d[, .(confidence)]
d[, !c('confidence')]
d[, sum(confidence)]
d[, .(mean(confidence), sd(confidence))]
d[, .(conf_mean = mean(confidence), conf_sd = sd(confidence))]
## pretend like we have gender information
d[, gender := ifelse(ppt %% 2, 'male', 'female')]
d
## first add a junk column
d[, junk := NA]
d
## remove junk
d[, junk := NULL]
d
d[, sum(confidence), .(ppt)]
d[, .(mean(confidence), sd(confidence)), .(question, gender)]
d[question==2, mean(confidence), .(gender)]
d[gender=='male', .(mean(confidence), sd(confidence)), .(question)]
d[, mean(confidence), .(gender)][gender=='male']
DT <- data.table(ID = c("b","b","b","a","a","c"), a = 1:6, b = 7:12, c = 13:18)
## We have to exclude the people that did not answer all 13 questions, because
## we don't know which question their answers correspsond too.
dd <- d[, .(confidence, question, .N), .(ppt)][N==13]
dd
g <- ggplot(data=dd, mapping=aes(x=question, y=confidence))
g
g + geom_point()
g <- ggplot(data=dd, mapping=aes(x=factor(question), y=confidence)) +
geom_point()
g
g <- ggplot(data=dd, mapping=aes(x=factor(question), y=confidence, colour=ppt)) +
geom_point()
g
g <- ggplot(data=dd, mapping=aes(x=factor(question), y=confidence, colour=factor(ppt))) +
geom_point()
g
g <- ggplot(data=dd, mapping=aes(x=factor(question), y=confidence)) +
geom_point() +
facet_wrap(~ppt)
g
library(data.table)
library(ggplot2)
library(curl)
rm(list=ls())
fp <- paste("https://crossley.github.io/cogs2020/",
"data/criterion_learning/data_table/data_table_crit_learn.csv", sep="")
d <- fread(fp)
d
1 + 1
install.packages('htmlwidgets')
install.packages("htmlwidgets")
knit_with_parameters('~/Dropbox/Apps/Overleaf/mis_paper/code/inspect_results_2.Rmd')
?kable
aov_ha[1]
dd <- d[phase=='Adaptation', .(rt = mean(reaction_time),
mt = mean(movement_time),
pv = mean(peak_velocity),
ha = mean(hand_angle)),
.(subject, group, bin)]
## General data prep
library(knitr)
library(data.table)
library(ggplot2)
library(ez)
library(emmeans)
rm(list=ls())
## set type III sums of squares
options(contrasts = c("contr.sum", "contr.poly"))
## Data prep
d <- fread('../data/MIS_DATA_LONG_21122019.csv')
d[, subject := Subject]
d[group==1, subject := subject + 10]
d[, n := length(unique(subject)), .(group)]
d[phase == 'Adaptation', trial := trial + 198]
d[phase == 'Generalisation', trial := trial + 198 + 110]
bin_size = 11
d[, bin := rep(1:(max(trial)/bin_size), each=bin_size), .(group, subject)]
d[rot_direction=='CW', hand_angle := -hand_angle]
d[, subject := factor(subject)]
d[, group := factor(group, levels=c(0,1), labels=c('Control', 'Expert'))]
d[, phase := factor(phase, levels=c('Base', 'Adaptation', 'Generalisation'))]
d[, target := factor(target)]
d[, condition := factor(condition)]
dd <- d[phase=='Adaptation', .(rt = mean(reaction_time),
mt = mean(movement_time),
pv = mean(peak_velocity),
ha = mean(hand_angle)),
.(subject, group, bin)]
dd[, subject := factor(subject)]
dd[, group := factor(group)]
dd[, bin := factor(bin)]
aov_ha <- ezANOVA(data=dd,
dv=ha,
wid=subject,
within=.(bin),
between=group,
type=3,
return_aov=T)
kable(aov_ha[1], caption='ANOVA')
kable(aov_ha[2])
kable(aov_ha[3])
aov_ha
str(aov_ha[[1]])
str(aov_ha[1])
str(aov_ha)
names(aov_ha)
names(aov_ha)[1]
Inf
x <- -100:100
fx <- dnorm(x)
ggplot(d, aes(x, fx)) +
geom_point()
ggplot(d, aes(x, fx)) +
geom_point()
library(dat.table)
library(data.table)
library(ggplot2)
x <- -100:100
fx <- dnorm(x)
d <- data.table(x, fx)
ggplot(d, aes(x, fx)) +
geom_point()
x <- -1:0.01:1
fx <- dnorm(x)
d <- data.table(x, fx)
ggplot(d, aes(x, fx)) +
geom_point()
x
x <- seq(-1, 1, 0.01)
fx <- dnorm(x)
d <- data.table(x, fx)
ggplot(d, aes(x, fx)) +
geom_point()
x <- seq(-10, 10, 0.01)
fx <- dnorm(x)
d <- data.table(x, fx)
ggplot(d, aes(x, fx)) +
geom_point()
?dnorm
x <- seq(-5, 5, 0.01)
fx <- dnorm(x)
d <- data.table(x, fx)
ggplot(d, aes(x, fx)) +
geom_point()
---
title: "Lecture 7"
author: "Author: Matthew J. Cossley"
date: "Last update: `r format(Sys.time(), '%d %B, %Y')`"
output:
html_document:
toc: true
toc_float:
collapsed: true
smooth_scroll: true
toc_depth: 3
fig_caption: yes
# code_folding: show
number_sections: false
theme: cerulean
fontsize: 14pt
---
## The Normal Distribution
x <- seq(-5, 5, 0.01)
x <- seq(-5, 5, 0.01)
fx <- dnorm(x)
d <- data.table(x, fx)
ggplot(d, aes(x, fx)) +
geom_point()
?dbinom
d
dd
x <- seq(-5, 5, 0.01)
fx <- dnorm(x, 0, 1)
y <- seq(5, 15, 1)
fy <- dbinom(y, 15, 0.5)
d <- data.table(x, fx, y, fy)
dd <- melt(d, measure.vars=c('x','fx','y','fy'))
d
dd
dd <- melt(d, measure.vars=c('fx','fy'))
dd
dd <- melt(d, measure.vars=c('x','fx','y','fy'))
dd
dd
dd <- melt(d, id.vars=c('x','y'), measure.vars=c('fx','fy'))
dd
x <- seq(-5, 5, 0.01)
fx <- dnorm(x, 0, 1)
d_norm <- data.table(id='normal', x=x, fx=fx)
x <- seq(5, 15, 1)
fx <- dbinom(y, 15, 0.5)
d_binom <- data.table(id='binomial', x=x, fx=fx)
d_norm
d_binom
rbind(d_binom, d_norm)
dd <- rbind(d_binom, d_norm)
dd <- rbind(d_binom, d_norm)
ggplot(dd, aes(x, fx)) +
geom_point() +
facet_wrap(~id)
x <- seq(-5, 5, 0.01)
fx <- dnorm(x, 0, 1)
d_norm <- data.table(id='normal', x=x, fx=fx)
x <- seq(0, 15, 1)
fx <- dbinom(x, 15, 0.5)
d_binom <- data.table(id='binomial', x=x, fx=fx)
dd <- rbind(d_binom, d_norm)
ggplot(dd, aes(x, fx)) +
geom_point() +
facet_wrap(~id)
ggplot(dd, aes(x, fx)) +
geom_point() +
facet_wrap(~id, scales='free')
x <- seq(0, 15, 1)
fx <- dbinom(x, 15, 1/15)
d_binom <- data.table(id='binomial', x=x, fx=fx)
dd <- rbind(d_binom, d_norm)
ggplot(dd, aes(x, fx)) +
geom_point() +
facet_wrap(~id, scales='free')
x <- seq(-5, 5, 0.01)
fx <- dnorm(x, 0, 1)
d_norm <- data.table(id='normal', x=x, fx=fx)
x <- seq(0, 15, 1)
fx <- dbinom(x, 15, 0.5)
d_binom <- data.table(id='binomial', x=x, fx=fx)
dd <- rbind(d_binom, d_norm)
ggplot(dd, aes(x, fx)) +
geom_point() +
facet_wrap(~id, scales='free')
plot(cars)
plot(cars)
str(cars)
d
knitr::opts_chunk$set(echo = TRUE)
library(data.table)
library(curl)
d <- fread("https://crossley.github.io/cogs2020/data/criterion_learning/data_table/data_table_crit_learn.csv")
d
d
d[exp == 'Experiment 1'] == d[exp == 'Experiment 1']
d[exp == 'Experiment 1'] == d[exp == 'Experiment 2']
knitr::opts_chunk$set(echo = TRUE)
d <- fread('https://crossley.github.io/cogs2020/data/criterion_learning/data_table/data_table_crit_learn.csv')
library(data.table)
d <- fread('https://crossley.github.io/cogs2020/data/criterion_learning/data_table/data_table_crit_learn.csv')
d
i
d
d <- d[exp != 2]
d
d
d[, exp := NA]
d
d[, exp := NULL]
d
d[, unique(nps)]
d
?fwrite
fwrite(d, 'data/criterion_learning/data_table/data_table_crit_learn.csv')
d <- fread('https://crossley.github.io/cogs2020/data/criterion_learning/data_table/data_table_crit_learn.csv')
# d <- d[exp != 2]
# d[, exp := NULL]
# d[, unique(nps)]
d
library(data.table)
# d <- fread('https://crossley.github.io/cogs2020/data/criterion_learning/data_table/data_table_crit_learn.csv')
# d <- d[exp != 2]
# d[, exp := NULL]
# d[, unique(nps)]
# fwrite(d, 'data/criterion_learning/data_table/data_table_crit_learn.csv')
d <- fread('data/criterion_learning/data_table/data_table_crit_learn.csv')
d
load("~/Dropbox/teaching/2021/cogs2020/live_course_material/lecture_1.Rmd")
load("~/Dropbox/teaching/2021/cogs2020/live_course_material/lecture_1.Rmd")
library(data.table)
rand()
randu()
library(data.table)
x <- c('I', 'I', 'I', 'II', 'II', 'II',)
library(data.table)
x <- c('I', 'I', 'I', 'II', 'II', 'II')
y <- c('a', 'a', 'b', 'b', 'c', 'c')
z <- 1:6
d <- data.table(x, y, z)
d
library(data.table)
x <- c('I', 'I', 'I', 'II', 'II', 'II', 'III', 'III', 'III', 'IV', 'IV', 'IV', 'IV')
y <- c('a', 'a', 'b', 'b', 'c', 'c', 'd', 'd', 'e', 'e', 'f', 'f')
z <- 1:12
d <- data.table(x, y, z)
d[x=='II']
library(data.table)
x <- c('I', 'I', 'I', 'II', 'II', 'II', 'III', 'III', 'III', 'IV', 'IV', 'IV')
y <- c('a', 'a', 'b', 'b', 'c', 'c', 'd', 'd', 'e', 'e', 'f', 'f')
z <- 1:12
d <- data.table(x, y, z)
d[x=='II']
library(data.table)
x <- c('I', 'I', 'I', 'II', 'II', 'II', 'III', 'III', 'III', 'IV', 'IV', 'IV')
y <- c('a', 'a', 'b', 'b', 'c', 'c', 'd', 'd', 'e', 'e', 'f', 'f')
z <- 1:12
d <- data.table(x, y, z)
d[x=='II']
d[, y]
library(data.table)
x <- c('I', 'I', 'I', 'II', 'II', 'II', 'III', 'III', 'III', 'IV', 'IV', 'IV')
y <- c('a', 'a', 'b', 'b', 'c', 'c', 'd', 'd', 'e', 'e', 'f', 'f')
z <- 1:12
d <- data.table(x, y, z)
d[x=='II']
d[, y]
d[, .(y)]
library(data.table)
x <- c('I', 'I', 'I', 'II', 'II', 'II', 'III', 'III', 'III', 'IV', 'IV', 'IV')
y <- c('a', 'a', 'b', 'b', 'c', 'c', 'd', 'd', 'e', 'e', 'f', 'f')
z <- 1:12
d <- data.table(x, y, z)
d[x=='II']
d[, y]
d[, .(y)]
d[, .(x, y)]
library(data.table)
x <- c('I', 'I', 'I', 'II', 'II', 'II', 'III', 'III', 'III', 'IV', 'IV', 'IV')
y <- c('a', 'a', 'b', 'b', 'c', 'c', 'd', 'd', 'e', 'e', 'f', 'f')
z <- 1:12
d <- data.table(x, y, z)
d[x=='II']
d[, y]
d[, .(y)]
d[, .(y, z)]
d[x=='II', .(y, z)]
library(data.table)
x <- c('I', 'I', 'I', 'II', 'II', 'II', 'III', 'III', 'III', 'IV', 'IV', 'IV')
y <- c('a', 'a', 'b', 'b', 'c', 'c', 'd', 'd', 'e', 'e', 'f', 'f')
z <- 1:12
d <- data.table(x, y, z)
d[x=='II']
d[, y]
d[, .(y)]
d[, .(y, z)]
d[x=='II', .(y, z)]
d[, z, .(x)]
library(data.table)
x <- c('I', 'I', 'I', 'II', 'II', 'II', 'III', 'III', 'III', 'IV', 'IV', 'IV')
y <- c('a', 'a', 'b', 'b', 'c', 'c', 'd', 'd', 'e', 'e', 'f', 'f')
z <- 1:12
d <- data.table(x, y, z)
d[x=='II']
d[, y]
d[, .(y)]
d[, .(y, z)]
d[x=='II', .(y, z)]
d[, sum(z), .(x)]
d
d[, sum(z), .(x)]
d[, sum(z), .(x, y)]
install.packages(c('data.table', 'ggplot2'))
install.packages('curl')
rnorm()
rnorm(10)
knitr::opts_chunk$set(echo = TRUE)
x <- list(3.14159, 'pi', TRUE)
x
class(1)
class(FALSE)
class(c(1, 2, 3))
'a' + 'b'
TRUE + FALSE
?data.frame
c('a', 1)
ls()
?ls
?rm()
# Create a three element list containing one numeric
# item, one `character` item, and one logical item.
x <- list(3.14159, 'pi', TRUE)
x
x
x[1]
class(x[1])
x[1][1]
x[1][[1]]
?c()
?vector
vector(10, 'numeric')
vector('numeric', 10)
list()
list(1)
?list
vector(1, 2, 3)
integer(3)
class(3)
class(integer(3))
class(TRUE)
dt
dt
?dt
# create a data table
dt <- data.table(x, y, z)
# Load the data.table library
library(data.table)
# create a data table
dt <- data.table(x, y, z)
# Create vectors to later store in a data frame
x <- c('I', 'I', 'I', 'II', 'II', 'II', 'III', 'III', 'III', 'IV', 'IV', 'IV')
y <- c('a', 'a', 'b', 'b', 'c', 'c', 'd', 'd', 'e', 'e', 'f', 'f')
z <- rnorm(12)
# Create the data frame
df <- data.frame(x, y, z)
df
# Access column x
df$x
# Load the data.table library
library(data.table)
# create a data table
dt <- data.table(x, y, z)
dt
# Select rows by passing integer indices
dt[c(2, 4)]
# Select rows by pass a logical expression
dt[x=='II']
dt
# Mix and match
dt[x=='II' & c(2, 4)]
dt
# Mix and match
dt[x=='II' & y=='b']
https://upload.wikimedia.org/wikipedia/commons/e/e8/Jk_bluesteel.jpg
dt[x=='II' & y=='b']
dt[, x]
dt[, .(x)]
dt[, .(unique(x), mean(z))]
dt[, .(sum(z), mean(z))]
mean(c('a', 'b'))
dt
reticulate::repl_python()
import sys
install.packages('reticulate')
reticulate::repl_python()
library(data.table)
install.packages('data.table')
install.packages("data.table")
\begin{align}
C_M \frac{dV}{dt} &= I - I_i \\
&= I - \sum_{ion} I_{ion}
\end{align}
$$\beta_m{V} = $4 e^{V_{\text{rest}}-V}$
library(reticulate)
use_python('/Users/mq20185996/miniconda3/bin/python')
reticulate::repl_python()
import numpy as np
reticulate::repl_python()
reticulate::repl_python()
